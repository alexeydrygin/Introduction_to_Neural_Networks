{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (50000, 32, 32, 3)\n",
      "50000 тренировочные примеры\n",
      "10000 тестовые примеры\n",
      "Epoch 1/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 25ms/step - accuracy: 0.0985 - loss: 2.8978 - val_accuracy: 0.1000 - val_loss: 2.3026\n",
      "Epoch 2/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 24ms/step - accuracy: 0.0980 - loss: 2.3029 - val_accuracy: 0.1000 - val_loss: 2.3025\n",
      "Epoch 3/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 24ms/step - accuracy: 0.0962 - loss: 2.3028 - val_accuracy: 0.1185 - val_loss: 2.3025\n",
      "Epoch 4/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 24ms/step - accuracy: 0.0978 - loss: 2.3028 - val_accuracy: 0.1004 - val_loss: 2.3025\n",
      "Epoch 5/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 24ms/step - accuracy: 0.1024 - loss: 2.3026 - val_accuracy: 0.1000 - val_loss: 2.3026\n",
      "Epoch 6/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 24ms/step - accuracy: 0.0975 - loss: 2.3028 - val_accuracy: 0.1111 - val_loss: 2.3025\n",
      "Epoch 7/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 24ms/step - accuracy: 0.0967 - loss: 2.3028 - val_accuracy: 0.1173 - val_loss: 2.3025\n",
      "Epoch 8/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 25ms/step - accuracy: 0.0991 - loss: 2.3028 - val_accuracy: 0.1051 - val_loss: 2.3025\n",
      "Epoch 9/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 24ms/step - accuracy: 0.1001 - loss: 2.3027 - val_accuracy: 0.1007 - val_loss: 2.3025\n",
      "Epoch 10/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 24ms/step - accuracy: 0.1017 - loss: 2.3026 - val_accuracy: 0.1085 - val_loss: 2.3025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Обученная модель сохранена как h:\\Git\\Introduction_to_Neural_Networks\\seminar-4\\saved_models\\keras_cifar10_trained_model.h5 \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.1080 - loss: 2.3025\n",
      "Test loss: 2.30247163772583\n",
      "Test accuracy: 0.10849999636411667\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D\n",
    "import os\n",
    "\n",
    "# Установка параметров нейросети\n",
    "batch_size = 32\n",
    "num_classes = 10\n",
    "epochs = 10  # Увеличиваем количество эпох для лучшего обучения\n",
    "data_augmentation = True\n",
    "save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
    "model_name = 'keras_cifar10_trained_model.h5'\n",
    "\n",
    "# Загрузка и разделение данных\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'тренировочные примеры')\n",
    "print(x_test.shape[0], 'тестовые примеры')\n",
    "\n",
    "# Преобразование матрицы чисел 0-9 в бинарную матрицу чисел 0-1\n",
    "y_train = tf.keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "# Нормализация данных\n",
    "x_train = x_train.astype('float32') / 255\n",
    "x_test = x_test.astype('float32') / 255\n",
    "\n",
    "# Определение формы входных данных\n",
    "input_shape = (32, 32, 3)  # Форма для CIFAR-10\n",
    "\n",
    "# Конфигурирование модели с использованием Input слоя\n",
    "model = Sequential()\n",
    "model.add(Input(shape=input_shape))\n",
    "model.add(Conv2D(32, (3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "# Компиляция модели\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Создание генератора данных с аугментацией\n",
    "if data_augmentation:\n",
    "    datagen = ImageDataGenerator(\n",
    "        rotation_range=10,\n",
    "        width_shift_range=0.1,\n",
    "        height_shift_range=0.1,\n",
    "        horizontal_flip=True,\n",
    "        preprocessing_function=tf.keras.applications.vgg16.preprocess_input\n",
    "    )\n",
    "    train_generator = datagen.flow(x_train, y_train, batch_size=batch_size)\n",
    "    model.fit(train_generator, epochs=epochs, validation_data=(x_test, y_test))\n",
    "else:\n",
    "    model.fit(x_train, y_train, batch_size=batch_size,\n",
    "              epochs=epochs, validation_data=(x_test, y_test))\n",
    "\n",
    "# Сохранение модели\n",
    "if not os.path.isdir(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "model_path = os.path.join(save_dir, model_name)\n",
    "model.save(model_path)\n",
    "print('Обученная модель сохранена как %s ' % model_path)\n",
    "\n",
    "# Оценка модели\n",
    "scores = model.evaluate(x_test, y_test, verbose=1)\n",
    "print('Test loss:', scores[0])\n",
    "print('Test accuracy:', scores[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Анализ  \n",
    "- Улучшает работу нейронной сети: Увеличение количества эпох, добавление фильтров, использование аугментации данных, Dropout, Batch Normalization, различные оптимизаторы и регуляризация.\n",
    "- Ухудшает работу нейронной сети: Слишком большое количество эпох может привести к переобучению, что ухудшит способность модели к обобщению на новых данных.  \n",
    "Применение этих стратегий может помочь улучшить точность распознавания образов CIFAR-10 сверточной нейронной сетью, но важно тщательно настраивать параметры и экспериментировать, чтобы найти оптимальную конфигурацию для вашей конкретной задачи."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (50000, 32, 32, 3)\n",
      "50000 тренировочные примеры\n",
      "10000 тестовые примеры\n",
      "Epoch 1/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 38ms/step - accuracy: 0.2559 - loss: 2.2255 - val_accuracy: 0.1000 - val_loss: 65.7148\n",
      "Epoch 2/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 38ms/step - accuracy: 0.4642 - loss: 1.4826 - val_accuracy: 0.1000 - val_loss: 15.4732\n",
      "Epoch 3/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 38ms/step - accuracy: 0.5457 - loss: 1.2739 - val_accuracy: 0.1000 - val_loss: 4.1524\n",
      "Epoch 4/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 39ms/step - accuracy: 0.5851 - loss: 1.1636 - val_accuracy: 0.1000 - val_loss: 21.5107\n",
      "Epoch 5/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 39ms/step - accuracy: 0.6215 - loss: 1.0697 - val_accuracy: 0.1000 - val_loss: 14.5576\n",
      "Epoch 6/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 41ms/step - accuracy: 0.6439 - loss: 1.0119 - val_accuracy: 0.1000 - val_loss: 18.8449\n",
      "Epoch 7/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 40ms/step - accuracy: 0.6616 - loss: 0.9642 - val_accuracy: 0.1001 - val_loss: 22.1160\n",
      "Epoch 8/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 42ms/step - accuracy: 0.6785 - loss: 0.9158 - val_accuracy: 0.1000 - val_loss: 32.4736\n",
      "Epoch 9/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 39ms/step - accuracy: 0.6910 - loss: 0.8791 - val_accuracy: 0.1000 - val_loss: 27.2754\n",
      "Epoch 10/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 39ms/step - accuracy: 0.7035 - loss: 0.8451 - val_accuracy: 0.1000 - val_loss: 24.3877\n",
      "Epoch 11/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 39ms/step - accuracy: 0.7096 - loss: 0.8283 - val_accuracy: 0.1000 - val_loss: 77.8753\n",
      "Epoch 12/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 39ms/step - accuracy: 0.7132 - loss: 0.8141 - val_accuracy: 0.1000 - val_loss: 54.5263\n",
      "Epoch 13/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 39ms/step - accuracy: 0.7238 - loss: 0.7983 - val_accuracy: 0.1000 - val_loss: 98.6707\n",
      "Epoch 14/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 39ms/step - accuracy: 0.7260 - loss: 0.7846 - val_accuracy: 0.1002 - val_loss: 52.0911\n",
      "Epoch 15/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 39ms/step - accuracy: 0.7340 - loss: 0.7611 - val_accuracy: 0.1000 - val_loss: 41.1908\n",
      "Epoch 16/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 40ms/step - accuracy: 0.7345 - loss: 0.7591 - val_accuracy: 0.1000 - val_loss: 72.6250\n",
      "Epoch 17/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 39ms/step - accuracy: 0.7431 - loss: 0.7473 - val_accuracy: 0.1000 - val_loss: 38.9105\n",
      "Epoch 18/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 39ms/step - accuracy: 0.7452 - loss: 0.7377 - val_accuracy: 0.1000 - val_loss: 79.3258\n",
      "Epoch 19/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 39ms/step - accuracy: 0.7512 - loss: 0.7204 - val_accuracy: 0.1000 - val_loss: 33.8832\n",
      "Epoch 20/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 39ms/step - accuracy: 0.7520 - loss: 0.7150 - val_accuracy: 0.1000 - val_loss: 76.6915\n",
      "Epoch 21/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 39ms/step - accuracy: 0.7518 - loss: 0.7078 - val_accuracy: 0.1000 - val_loss: 107.2710\n",
      "Epoch 22/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 39ms/step - accuracy: 0.7523 - loss: 0.7068 - val_accuracy: 0.1000 - val_loss: 96.2464\n",
      "Epoch 23/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 39ms/step - accuracy: 0.7622 - loss: 0.6912 - val_accuracy: 0.1000 - val_loss: 47.6459\n",
      "Epoch 24/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 38ms/step - accuracy: 0.7648 - loss: 0.6824 - val_accuracy: 0.1000 - val_loss: 56.4297\n",
      "Epoch 25/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 39ms/step - accuracy: 0.7645 - loss: 0.6720 - val_accuracy: 0.1000 - val_loss: 79.9038\n",
      "Epoch 26/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 38ms/step - accuracy: 0.7656 - loss: 0.6782 - val_accuracy: 0.1038 - val_loss: 54.1492\n",
      "Epoch 27/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 39ms/step - accuracy: 0.7642 - loss: 0.6791 - val_accuracy: 0.1115 - val_loss: 93.0400\n",
      "Epoch 28/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 39ms/step - accuracy: 0.7679 - loss: 0.6679 - val_accuracy: 0.1000 - val_loss: 93.1818\n",
      "Epoch 29/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 39ms/step - accuracy: 0.7706 - loss: 0.6605 - val_accuracy: 0.1000 - val_loss: 117.0356\n",
      "Epoch 30/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 39ms/step - accuracy: 0.7690 - loss: 0.6660 - val_accuracy: 0.1000 - val_loss: 150.5572\n",
      "Epoch 31/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 39ms/step - accuracy: 0.7739 - loss: 0.6534 - val_accuracy: 0.1000 - val_loss: 148.0789\n",
      "Epoch 32/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 39ms/step - accuracy: 0.7757 - loss: 0.6481 - val_accuracy: 0.1000 - val_loss: 91.4286\n",
      "Epoch 33/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 39ms/step - accuracy: 0.7778 - loss: 0.6458 - val_accuracy: 0.1000 - val_loss: 186.2317\n",
      "Epoch 34/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 39ms/step - accuracy: 0.7828 - loss: 0.6301 - val_accuracy: 0.1000 - val_loss: 165.5038\n",
      "Epoch 35/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 39ms/step - accuracy: 0.7816 - loss: 0.6262 - val_accuracy: 0.1000 - val_loss: 150.4993\n",
      "Epoch 36/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 39ms/step - accuracy: 0.7833 - loss: 0.6296 - val_accuracy: 0.1000 - val_loss: 124.9372\n",
      "Epoch 37/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 39ms/step - accuracy: 0.7794 - loss: 0.6345 - val_accuracy: 0.1000 - val_loss: 96.7891\n",
      "Epoch 38/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 39ms/step - accuracy: 0.7866 - loss: 0.6125 - val_accuracy: 0.1000 - val_loss: 102.8386\n",
      "Epoch 39/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 39ms/step - accuracy: 0.7899 - loss: 0.6095 - val_accuracy: 0.1000 - val_loss: 50.9502\n",
      "Epoch 40/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 41ms/step - accuracy: 0.7883 - loss: 0.6105 - val_accuracy: 0.1000 - val_loss: 200.1520\n",
      "Epoch 41/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 42ms/step - accuracy: 0.7894 - loss: 0.6149 - val_accuracy: 0.1000 - val_loss: 162.0888\n",
      "Epoch 42/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 43ms/step - accuracy: 0.7912 - loss: 0.6015 - val_accuracy: 0.1000 - val_loss: 145.4038\n",
      "Epoch 43/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 42ms/step - accuracy: 0.7908 - loss: 0.6025 - val_accuracy: 0.1000 - val_loss: 84.6581\n",
      "Epoch 44/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 42ms/step - accuracy: 0.7898 - loss: 0.6036 - val_accuracy: 0.1000 - val_loss: 145.3327\n",
      "Epoch 45/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 42ms/step - accuracy: 0.7914 - loss: 0.6063 - val_accuracy: 0.1000 - val_loss: 102.6514\n",
      "Epoch 46/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 43ms/step - accuracy: 0.7957 - loss: 0.5882 - val_accuracy: 0.1000 - val_loss: 101.2095\n",
      "Epoch 47/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 42ms/step - accuracy: 0.7918 - loss: 0.6026 - val_accuracy: 0.1000 - val_loss: 61.0431\n",
      "Epoch 48/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 41ms/step - accuracy: 0.7955 - loss: 0.5938 - val_accuracy: 0.1000 - val_loss: 77.5375\n",
      "Epoch 49/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 41ms/step - accuracy: 0.7984 - loss: 0.5898 - val_accuracy: 0.1000 - val_loss: 63.5840\n",
      "Epoch 50/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 41ms/step - accuracy: 0.8007 - loss: 0.5791 - val_accuracy: 0.1000 - val_loss: 104.0150\n",
      "Обученная модель сохранена как h:\\Git\\Introduction_to_Neural_Networks\\seminar-4\\saved_models\\keras_cifar10_trained_model.keras \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.0968 - loss: 105.2950\n",
      "Test loss: 104.01504516601562\n",
      "Test accuracy: 0.10000000149011612\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D, BatchNormalization\n",
    "import os\n",
    "\n",
    "# Установка параметров нейросети\n",
    "batch_size = 32\n",
    "num_classes = 10\n",
    "epochs = 50  # Увеличиваем количество эпох для лучшего обучения\n",
    "data_augmentation = True\n",
    "save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
    "# Изменено на рекомендуемый формат\n",
    "model_name = 'keras_cifar10_trained_model.keras'\n",
    "\n",
    "# Загрузка и разделение данных\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'тренировочные примеры')\n",
    "print(x_test.shape[0], 'тестовые примеры')\n",
    "\n",
    "# Преобразование матрицы чисел 0-9 в бинарную матрицу чисел 0-1\n",
    "y_train = tf.keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "# Нормализация данных\n",
    "x_train = x_train.astype('float32') / 255\n",
    "x_test = x_test.astype('float32') / 255\n",
    "\n",
    "# Определение формы входных данных\n",
    "input_shape = (32, 32, 3)  # Форма для CIFAR-10\n",
    "\n",
    "# Конфигурирование модели с использованием Input слоя и добавлением BatchNormalization\n",
    "model = Sequential()\n",
    "model.add(Input(shape=input_shape))\n",
    "model.add(Conv2D(32, (3, 3), padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "# Компиляция модели с использованием оптимизатора Adam\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Создание генератора данных с аугментацией\n",
    "if data_augmentation:\n",
    "    datagen = ImageDataGenerator(\n",
    "        rotation_range=10,\n",
    "        width_shift_range=0.1,\n",
    "        height_shift_range=0.1,\n",
    "        horizontal_flip=True,\n",
    "        preprocessing_function=tf.keras.applications.vgg16.preprocess_input\n",
    "    )\n",
    "    train_generator = datagen.flow(x_train, y_train, batch_size=batch_size)\n",
    "    model.fit(train_generator, epochs=epochs, validation_data=(x_test, y_test))\n",
    "else:\n",
    "    model.fit(x_train, y_train, batch_size=batch_size,\n",
    "              epochs=epochs, validation_data=(x_test, y_test))\n",
    "\n",
    "# Сохранение модели в новом формате\n",
    "if not os.path.isdir(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "model_path = os.path.join(save_dir, model_name)\n",
    "model.save(model_path)\n",
    "print('Обученная модель сохранена как %s ' % model_path)\n",
    "\n",
    "# Оценка модели\n",
    "scores = model.evaluate(x_test, y_test, verbose=1)\n",
    "print('Test loss:', scores[0])\n",
    "print('Test accuracy:', scores[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В этом коде были внесены следующие изменения:  \n",
    "\n",
    "- Увеличено количество эпох обучения до 50 для лучшего обучения модели.\n",
    "- Добавлены слои BatchNormalization после каждого сверточного слоя для улучшения обучения и стабильности модели.\n",
    "- Использован оптимизатор adam для более эффективного обучения.\n",
    "- Включена аугментация данных для увеличения разнообразия обучающих данных.\n",
    "- Изменено имя файла сохранения модели на .keras, что является рекомендуемым форматом для сохранения моделей Keras.  \n",
    "\n",
    "Эти изменения направлены на улучшение обучения модели и ее способности к обобщению на новых данных, что в свою очередь может улучшить точность распознавания образов CIFAR-10."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Для работы с другими наборами данных, такими как MNIST, CIFAR-100 и ImageNet, потребуется внести изменения в архитектуру нейронной сети и параметры обучения. Вот некоторые рекомендации:**  \n",
    "\n",
    "\n",
    "**MNIST**  \n",
    "Изменение размера входных данных: MNIST состоит из изображений размером 28x28 пикселей, в отличие от CIFAR-10, где изображения имеют размер 32x32 пикселей. Нужно будет изменить размер входных данных в модели.\n",
    "Изменение количества классов: MNIST содержит 1 класс (цифры от 0 до 9), в то время как CIFAR-10 содержит 10 классов. Это означает, что вам нужно будет изменить количество нейронов в последнем полносвязном слое на 10.\n",
    "\n",
    "**CIFAR-100**  \n",
    "Увеличение количества фильтров: CIFAR-100 содержит 100 классов, что значительно больше, чем в CIFAR-10. Может потребоваться увеличить количество фильтров в сверточных слоях, чтобы модель могла лучше различать различные классы.\n",
    "Использование более глубокой архитектуры: Для CIFAR-100 может потребоваться более глубокая архитектура, чтобы улучшить производительность модели.\n",
    "\n",
    "**ImageNet**  \n",
    "Использование предварительно обученных моделей: ImageNet содержит огромное количество изображений и классов, что делает его сложным для обучения с нуля. Вместо этого рекомендуется использовать предварительно обученные модели, такие как VGG16, ResNet или Inception, и дообучать их на наборе данных.\n",
    "Изменение размера входных данных: ImageNet содержит изображения размером 224x224 пикселей, поэтому нужно будет изменить размер входных данных в модели.  \n",
    "\n",
    "**Общие рекомендации**  \n",
    "Использование активационной функции ELU: Вместо ReLU можно использовать ELU (Exponential Linear Unit), которая может ускорить процесс обучения и улучшить точность модели, особенно на сложных наборах данных, таких как CIFAR-100 3.  \n",
    "Оптимизация параметров обучения: Может потребоваться оптимизация параметров обучения, таких как скорость обучения, размер пакета и количество эпох, чтобы достичь лучшей производительности на новых наборах данных.  \n",
    "При переносе модели на другие наборы данных важно тщательно тестировать и настраивать модель, чтобы обеспечить её эффективную работу на каждом из них.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
