{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В этом примере я буду использовать модель, основанную на сверточных нейронных сетях, с добавлением дополнительных сверточных слоев, использованием Dropout для предотвращения переобучения и регуляризации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mДля выполнения ячеек с \"c:\\Users\\Alex\\AppData\\Local\\Programs\\Python\\Python313\\python.exe\" требуется пакет ipykernel.\n",
      "\u001b[1;31mВыполните следующую команду, чтобы установить \"ipykernel\" в среде Python. \n",
      "\u001b[1;31mКоманда: \"c:/Users/Alex/AppData/Local/Programs/Python/Python313/python.exe -m pip install ipykernel -U --user --force-reinstall\""
     ]
    }
   ],
   "source": [
    "# Импорт необходимых библиотек\n",
    "import keras\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from keras.models import Sequential\n",
    "from keras.utils import to_categorical\n",
    "from keras.optimizers import Adam\n",
    "from keras.regularizers import l2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Загрузка и подготовка данных\n",
    "# Загружаем данные Fashion-MNIST, нормализуем их \n",
    "# и преобразуем метки классов в категориальный формат.\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.fashion_mnist.load_data()\n",
    "x_train = x_train / 255.0\n",
    "x_test = x_test / 255.0\n",
    "y_train = to_categorical(y_train, num_classes=10)\n",
    "y_test = to_categorical(y_test, num_classes=10)\n",
    "\n",
    "# Определение архитектуры модели\n",
    "# Создаем модель с несколькими сверточными слоями, \n",
    "# добавляем Dropout для предотвращения переобучения \n",
    "# и регуляризацию L2 для весов полносвязных слоев.\n",
    "input_shape = (28, 28, 1)\n",
    "model = Sequential([\n",
    "    # Первый сверточный слой с 32 фильтрами, padding='same' для сохранения размерности\n",
    "    Conv2D(32, kernel_size=(3, 3), activation='relu',\n",
    "           padding='same', input_shape=input_shape),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    # Второй сверточный слой с 64 фильтрами\n",
    "    Conv2D(64, kernel_size=(3, 3), activation='relu', padding='same'),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    # Третий сверточный слой с 128 фильтрами\n",
    "    Conv2D(128, kernel_size=(3, 3), activation='relu', padding='same'),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    # Dropout слой для предотвращения переобучения\n",
    "    Dropout(0.5),\n",
    "    # Преобразование в одномерный массив\n",
    "    Flatten(),\n",
    "    # Полносвязный слой с 128 нейронами\n",
    "    Dense(128, activation='relu', kernel_regularizer=l2(0.001)),\n",
    "    # Выходной слой с 10 нейронами (для 10 классов)\n",
    "    Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "# Компиляция модели\n",
    "# Компилируем модель с оптимизатором Adam, \n",
    "# функцией потерь categorical_crossentropy и метрикой accuracy.\n",
    "model.compile(optimizer=Adam(), \n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Обучение модели\n",
    "# Обучаем модель на тренировочных данных \n",
    "# с использованием валидационных данных для мониторинга.\n",
    "history = model.fit(x_train, y_train, batch_size=32,\n",
    "                    epochs=10, validation_data=(x_test, y_test))\n",
    "\n",
    "# Визуализация результатов обучения\n",
    "# Визуализируем точность и потери модели во время обучения и валидации.\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Вывод информации о модели\n",
    "# Выводим информацию о структуре модели с помощью метода summary().\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Это улучшенная версия модели, которая включает в себя дополнительные сверточные слои, Dropout для предотвращения переобучения и регуляризацию для улучшения обобщающей способности модели."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Изучив документацию TensorFlow 2 и дополнительные ресурсы, можно выделить несколько полезных команд и функций, которые могут быть полезны для разработки и улучшения моделей машинного обучения. Эти команды не были разобранны на уроке, но они могут значительно улучшить ваш опыт работы с TensorFlow.\n",
    "\n",
    "\n",
    "1. **tf.keras.callbacks**\n",
    "Callbacks позволяют вам вставлять код, который будет выполняться в определенные моменты процесса обучения. Это может быть полезно для мониторинга процесса обучения, сохранения модели в процессе обучения, или для ранней остановки обучения, если модель перестает улучшаться.\n",
    "\n",
    "```\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "\n",
    "# Сохранение лучшей модели\n",
    "checkpoint = ModelCheckpoint('best_model.h5', monitor='val_loss', save_best_only=True)\n",
    "\n",
    "# Ранняя остановка обучения\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3)\n",
    "\n",
    "# Использование callbacks при обучении модели\n",
    "model.fit(x_train, y_train, epochs=10, callbacks=[checkpoint, early_stopping])\n",
    "```\n",
    "\n",
    "2. **tf.keras.regularizers**\n",
    "Регуляризация помогает предотвратить переобучение модели, добавляя штраф к весам модели. Примеры регуляризаторов включают L1, L2, и L1_L2.\n",
    "\n",
    "```\n",
    "from tensorflow.keras.regularizers import l1, l2, l1_l2\n",
    "\n",
    "# Применение L2 регуляризации к полносвязному слою\n",
    "model.add(Dense(64, activation='relu', kernel_regularizer=l2(0.01)))\n",
    "```\n",
    "\n",
    "3. **tf.keras.metrics**\n",
    "Метрики позволяют оценивать производительность модели во время обучения и тестирования. TensorFlow предлагает широкий спектр метрик, включая accuracy, AUC, Precision, Recall, и многие другие.\n",
    "\n",
    "```\n",
    "from tensorflow.keras.metrics import AUC, Precision, Recall\n",
    "\n",
    "# Использование метрик при компиляции модели\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=[AUC(), Precision(), Recall()])\n",
    "```\n",
    "\n",
    "4. **tf.keras.losses**\n",
    "TensorFlow предоставляет различные функции потерь, которые можно использовать в зависимости от задачи обучения. Например, categorical_crossentropy для задач классификации, mean_squared_error для задач регрессии, и binary_crossentropy для бинарной классификации.\n",
    "\n",
    "```\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy, MeanSquaredError, BinaryCrossentropy\n",
    "\n",
    "# Пример использования функции потерь\n",
    "model.compile(optimizer='adam', loss=CategoricalCrossentropy(), metrics=['accuracy'])\n",
    "```\n",
    "Эти команды и функции могут значительно расширить возможности моделей машинного обучения, позволяя более гибко управлять процессом обучения и оценивать производительность модели."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
